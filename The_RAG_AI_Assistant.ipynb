{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478bd733-cd27-4efa-9096-e92e3bb2c4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Current Kernel: C:\\Users\\udeko\\anaconda3\\python.exe\n",
      "‚úÖ sentencepiece is now active!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"üí° Current Kernel:\", sys.executable)\n",
    "import sentencepiece\n",
    "print(\"‚úÖ sentencepiece is now active!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f950e2d-ab75-4979-86c3-f7eb1b8176aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load FLAN-T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model_t5 = T5ForConditionalGeneration.fr=om_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "print(\"‚úÖ Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee9e6d-9204-4f43-bd31-9fa7281d614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, context):\n",
    "    prompt = f\"question: {question}\\ncontext: {context}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model_t5.generate(**inputs, max_new_tokens=60)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Pull a question + context from your dataset\n",
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\udeko\\.cache\\kagglehub\\datasets\\frankossai\\natural-questions-dataset\\versions\\1\"\n",
    "df = pd.read_csv(f\"{path}/Natural-Questions-Filtered.csv\")\n",
    "\n",
    "sample_q = df.iloc[1][\"question\"]\n",
    "sample_context = df.iloc[1][\"long_answers\"]\n",
    "\n",
    "generated_answer = generate_answer(sample_q, sample_context)\n",
    "\n",
    "print(\"üß† Question:\", sample_q)\n",
    "print(\"üí¨ Generated Answer:\", generated_answer)\n",
    "print(\"‚úÖ True Answer:\", df.iloc[1]['short_answers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b59d8-455d-450b-ab6c-9caca4202c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(df, n_samples=10):\n",
    "    correct = 0\n",
    "    total = min(n_samples, len(df))\n",
    "\n",
    "    for i in range(total):\n",
    "        q = df.iloc[i][\"question\"]\n",
    "        context = df.iloc[i][\"long_answers\"]\n",
    "        true_answer = str(df.iloc[i][\"short_answers\"]).strip().lower()\n",
    "        \n",
    "        generated = generate_answer(q, context).strip().lower()\n",
    "        \n",
    "        is_correct = true_answer in generated or generated in true_answer\n",
    "        correct += int(is_correct)\n",
    "        \n",
    "        print(f\"\\nüß† Q{i+1}: {q}\")\n",
    "        print(f\"üí¨ Generated: {generated}\")\n",
    "        print(f\"‚úÖ True: {true_answer}\")\n",
    "        print(f\"üéØ Match: {'Yes' if is_correct else 'No'}\")\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f\"\\nüìä Accuracy over {total} samples: {accuracy:.2f}%\")\n",
    "\n",
    "# Run evaluation on first 10 samples\n",
    "evaluate_model(df, n_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d5d58-1348-414f-886d-639a3ec5368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Use a lightweight embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode all long answers\n",
    "embeddings = embedder.encode(df['long_answers'].tolist(), show_progress_bar=True)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Create FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"‚úÖ Indexed\", index.ntotal, \"contexts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d432c9-5553-482a-957e-eef62a4fb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your dataset\n",
    "path = r\"C:\\Users\\udeko\\.cache\\kagglehub\\datasets\\frankossai\\natural-questions-dataset\\versions\\1\"\n",
    "\n",
    "# Load the filtered dataset\n",
    "df = pd.read_csv(f\"{path}/Natural-Questions-Filtered.csv\")\n",
    "print(\"‚úÖ Dataset loaded. Rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc64ab1-a9d9-47f6-9547-0a7e81b4d5cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = embedder.encode(df['long_answers'].tolist(), show_progress_bar=True)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"‚úÖ Indexed\", index.ntotal, \"contexts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf258ca-15a2-4bf4-8786-c99e80e5a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load FLAN-T5 model and tokenizer again\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "print(\"‚úÖ Model and tokenizer reloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aaf6c4-d6f2-4779-8dae-c8f774ccdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, context):\n",
    "    prompt = f\"question: {question}\\ncontext: {context}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model_t5.generate(**inputs, max_new_tokens=60)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c94aa-7460-4829-9477-2ccce28c3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(question, k=a3):\n",
    "    contexts = retrieve_context(question, k)\n",
    "    combined_context = \" \".join(contexts)\n",
    "    return generate_answer(question, combined_context)\n",
    "\n",
    "# Test example\n",
    "query = \"who is the president of un general assembly\"\n",
    "print(\"üß† Question:\", query)\n",
    "print(\"üí¨ RAG Answer:\", rag_answer(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ba009-1cef-40ef-b294-0d15dfa51a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(question, k=3):\n",
    "    contexts = retrieve_context(question, k)\n",
    "    combined_context = \" \".join(contexts)\n",
    "    return generate_answer(question, combined_context)\n",
    "\n",
    "# Test example\n",
    "query = \"who is the president of un general assembly\"\n",
    "print(\"üß† Question:\", query)\n",
    "print(\"üí¨ RAG Answer:\", rag_answer(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6f398-c1d1-496b-accb-15c50291e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_answer(\"who is the president of un general assembly\", k=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c69cf4-99a6-44a3-b04e-389710129ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(question, k=5):\n",
    "    contexts = retrieve_context(question, k)\n",
    "    combined_context = \" [SEP] \".join(contexts)  # separates retrieved chunks\n",
    "    answer = generate_answer(question, combined_context)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708a475-165e-4ec6-b999-d9f7d5e1d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(question, k=3):\n",
    "    q_vec = embedder.encode([question]).astype('float32')\n",
    "    distances, indices = index.search(q_vec, k)\n",
    "    return [df.iloc[i]['long_answers'] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682236a-5099-4df8-9be8-5deee8484e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_answer(\"who is the president of un general assembly\", k=5))\n",
    "import random\n",
    "\n",
    "# ‚úÖ Step 10: Evaluate RAG vs Original T5 Baseline\n",
    "sample_questions = [\n",
    "    \"who is the president of un general assembly\",\n",
    "    \"what is the capital of ghana\",\n",
    "    \"when was covid 19 first declared a pandemic\",\n",
    "    \"who painted the mona lisa\",\n",
    "    \"what is the largest planet in our solar system\",\n",
    "    \"who wrote romeo and juliet\",\n",
    "    \"where is mount everest located\",\n",
    "    \"when did world war 2 end\",\n",
    "    \"what language is spoken in brazil\",\n",
    "    \"who founded microsoft\"\n",
    "]\n",
    "\n",
    "# Ground truth answers (for reference)\n",
    "true_answers = [\n",
    "    \"dennis francis\",\n",
    "    \"accra\",\n",
    "    \"march 11, 2020\",\n",
    "    \"leonardo da vinci\",\n",
    "    \"jupiter\",\n",
    "    \"william shakespeare\",\n",
    "    \"nepal\",\n",
    "    \"1945\",\n",
    "    \"portuguese\",\n",
    "    \"bill gates\"\n",
    "]\n",
    "\n",
    "# Evaluate both models\n",
    "results = []\n",
    "for i, q in enumerate(sample_questions):\n",
    "    print(f\"üß† Q{i+1}: {q}\")\n",
    "    rag = rag_answer(q, k=5)\n",
    "    \n",
    "    print(\"üí¨ RAG Answer:\", rag)\n",
    "    print(\"‚úÖ True:\", true_answers[i])\n",
    "    \n",
    "    match = true_answers[i].lower() in rag.lower()\n",
    "    print(\"üéØ Match:\", \"Yes\" if match else \"No\")\n",
    "    print(\"-\" * 80)\n",
    "    results.append(match)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = (sum(results) / len(results)) * 100\n",
    "print(f\"\\nüìä Overall RAG Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a79fa2-f2b0-4059-9138-d086bb0bc744",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_context = \"The current President of the UN General Assembly (2024‚Äì2025) is Dennis Francis of Trinidad and Tobago.\"\n",
    "print(rag_answer(\"who is the president of un general assembly\", k=5) + \"\\n\" + extra_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac979a9b-a179-471f-9026-ae4bbb222305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11 ‚Äì Live Context Augmentation for RAG\n",
    "\n",
    "# 1. Install and import Wikipedia API library\n",
    "!pip install wikipedia-api\n",
    "\n",
    "import wikipediaapi\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='DekkyVoyages-RAG', language='en')\n",
    "\n",
    "def fetch_wiki_context(topic, sentences=2):\n",
    "    page = wiki_wiki.page(topic)\n",
    "    if page.exists():\n",
    "        # return summary (first N sentences) + fulltext\n",
    "        summary = page.summary\n",
    "        return summary\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# 2. Augmented retrieval function\n",
    "def retrieve_augmented_context(question, k=3):\n",
    "    # retrieve from your indexed FAISS dataset\n",
    "    contexts = retrieve_context(question, k)\n",
    "    # extract a keyword/topic from question (simple heuristic)\n",
    "    # You might improve with proper keyword extraction\n",
    "    topic = question\n",
    "    wiki_context = fetch_wiki_context(topic, sentences=2)\n",
    "    if wiki_context:\n",
    "        contexts.insert(0, wiki_context)  # add wiki context first\n",
    "    combined = \" [SEP] \".join(contexts)\n",
    "    return combined\n",
    "\n",
    "# 3. Augmented RAG answer function\n",
    "def rag_answer_augmented(question, k=3):\n",
    "    combined_context = retrieve_augmented_context(question, k)\n",
    "    answer = generate_answer(question, combined_context)\n",
    "    return answer\n",
    "\n",
    "# 4. Test with a current-events question\n",
    "query = \"who is the president of un general assembly\"\n",
    "print(\"üß† Question:\", query)\n",
    "print(\"üí¨ Augmented RAG Answer:\", rag_answer_augmented(query, k=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5a062-a02d-4f27-8f57-d79c27dbff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wiki_context(topic, sentences=2):\n",
    "    import wikipedia\n",
    "    try:\n",
    "        summary = wikipedia.summary(topic, sentences=sentences, auto_suggest=True)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"(No wiki data found: {e})\"\n",
    "\n",
    "def rag_answer_augmented(question, k=3):\n",
    "    contexts = retrieve_context(question, k)\n",
    "    wiki_context = fetch_wiki_context(question, sentences=3)\n",
    "    combined_context = wiki_context + \" [SEP] \" + \" [SEP] \".join(contexts)\n",
    "    answer = generate_answer(question, combined_context)\n",
    "    return answer\n",
    "\n",
    "query = \"who is the president of un general assembly\"\n",
    "print(\"üß† Question:\", query)\n",
    "print(\"üí¨ Improved Augmented RAG Answer:\", rag_answer_augmented(query, k=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d576265-7212-4ae0-89bf-5b88e86b6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b700c-93c2-4cac-8ca3-49d8beac9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wiki_context(topic, sentences=2):\n",
    "```)  \n",
    "\n",
    "That‚Äôll activate the Wikipedia-enhanced RAG pipeline.  \n",
    "Let‚Äôs see if it now pulls **Dennis Francis (2024‚Äì2025)** as the correct UN General Assembly president! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03340d9c-6fcc-4166-baa6-f631cdf034ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wiki_context(topic, sentences=2):\n",
    "    import wikipedia\n",
    "    try:\n",
    "        summary = wikipedia.summary(topic, sentences=sentences, auto_suggest=True)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"(No wiki data found: {e})\"\n",
    "\n",
    "def rag_answer_augmented(question, k=3):\n",
    "    contexts = retrieve_context(question, k)\n",
    "    wiki_context = fetch_wiki_context(question, sentences=3)\n",
    "    combined_context = wiki_context + \" [SEP] \" + \" [SEP] \".join(contexts)\n",
    "    answer = generate_answer(question, combined_context)\n",
    "    return answer\n",
    "\n",
    "query = \"who is the president of un general assembly\"\n",
    "print(\"üß† Question:\", query)\n",
    "print(\"üí¨ Improved Augmented RAG Answer:\", rag_answer_augmented(query, k=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f28569-44d2-4a64-9768-cd74dc663a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_context = fetch_wiki_context(\"President of the United Nations General Assembly\", sentences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5175b3-5e02-4c74-86ae-5a81cf3bb1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Add the latest UN General Assembly President info\n",
    "new_row = {\n",
    "    \"question\": \"who is the president of the un general assembly\",\n",
    "    \"long_answers\": \"Annalena Baerbock of Germany was elected President of the United Nations General Assembly (80th session) on 2 June 2025 and will assume office on 9 September 2025.\"\n",
    "}\n",
    "\n",
    "# Append the new data\n",
    "df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Save updated dataset\n",
    "updated_path = f\"{path}/Natural-Questions-Filtered-Updated.csv\"\n",
    "df.to_csv(updated_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ New fact added and saved to: {updated_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1321e9-ce2c-4dcc-88e5-c26336d6456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Rebuild FAISS Index after adding new data\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Reload the updated dataset\n",
    "df = pd.read_csv(updated_path)\n",
    "\n",
    "# Re-embed all long answers\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedder.encode(df['long_answers'].tolist(), show_progress_bar=True)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Create new FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"‚úÖ Re-indexed {index.ntotal} contexts successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46a58c-8044-47c9-968c-5204cd48e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "  faiss.write_index(index, f\"{path}/natural_questions_index.faiss\")\n",
    "print(\"‚úÖ FAISS index saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff9b39-4302-4d52-b197-9e3e39ddc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# ‚úÖ Function that powers the RAG QA system\n",
    "def answer_question(query):\n",
    "    try:\n",
    "        rag_result = rag_answer_augmented(query, k=5)\n",
    "        return f\"üí¨ **Question:** {query}\\n\\nüß† **Answer:** {rag_result}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error: {str(e)}\"\n",
    "\n",
    "# ‚úÖ Build the Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=answer_question,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Ask a question...\"),\n",
    "    outputs=\"markdown\",\n",
    "    title=\"üß† RAG QA System with FLAN-T5 + Wikipedia\",\n",
    "    description=\"Ask factual questions and get context-aware answers powered by FAISS, FLAN-T5, and Wikipedia.\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Launch the app\n",
    "demo.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc5321-0a88-4068-83cc-b820bc058501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc64e4a-c0c4-4fa2-8aab-8dfb395b5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wiki_context(topic, sentences=2):\n",
    "    import wikipedia\n",
    "    try:\n",
    "        summary = wikipedia.summary(topic, sentences=sentences, auto_suggest=True)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"(No wiki data found: {e})\"\n",
    "\n",
    "def rag_answer_augmented(question, k=3):\n",
    "    contexts = retrieve_context(question, k)\n",
    "    wiki_context = fetch_wiki_context(question, sentences=3)\n",
    "    combined_context = wiki_context + \" [SEP] \" + \" [SEP] \".join(contexts)\n",
    "    answer = generate_answer(question, combined_context)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcb9a3-6d53-43c9-8068-c630992fb774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# ‚úÖ Function that powers the RAG QA system\n",
    "def answer_question(query):\n",
    "    try:\n",
    "        rag_result = rag_answer_augmented(query, k=5)\n",
    "        return f\"üí¨ **Question:** {query}\\n\\nüß† **Answer:** {rag_result}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error: {str(e)}\"\n",
    "\n",
    "# ‚úÖ Build the Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=answer_question,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Ask a question...\"),\n",
    "    outputs=\"markdown\",\n",
    "    title=\"üß† RAG QA System with FLAN-T5 + Wikipedia\",\n",
    "    description=\"Ask factual questions and get context-aware answers powered by FAISS, FLAN-T5, and Wikipedia.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9476c-77e2-4444-ad4b-0091bd1982d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5271e12-6f5b-48bb-bd2f-4ee2a0da7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch sentence-transformers faiss-cpu wikipedia gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481807d1-f225-4c0d-b4f4-a3184a45cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers faiss-cpu gradio sentence-transformers kagglehub torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5718663-a634-46cc-b0fb-aa68ac2ba370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udeko\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9befa154-4c26-47a1-a931-bd38c8a37e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\udeko\\anaconda3\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\udeko\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\udeko\\anaconda3\\lib\\site-packages (5.49.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\udeko\\anaconda3\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\udeko\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: torch in c:\\users\\udeko\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (4.7.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.121.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.6.4)\n",
      "Requirement already satisfied: gradio-client==1.13.3 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (1.13.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (2.10.3)\n",
      "Requirement already satisfied: pydub in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.49.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\udeko\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers faiss-cpu gradio sentence-transformers kagglehub torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b97004-b12d-4ad9-9617-409b8562bafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset downloaded to: C:\\Users\\udeko\\.cache\\kagglehub\\datasets\\frankossai\\natural-questions-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest Natural Questions dataset\n",
    "path = kagglehub.dataset_download(\"frankossai/natural-questions-dataset\")\n",
    "print(\"‚úÖ Dataset downloaded to:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ef2f6d-5346-42e4-85c9-7d6ce6174115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model and FLAN-T5 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import faiss, torch\n",
    "\n",
    "# Load models\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "print(\"‚úÖ Embedding model and FLAN-T5 loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3363fb4-4e93-43ee-bcea-e74e1968b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example docs (you can expand this later)\n",
    "docs = [\n",
    "    \"Penicillin was discovered by Alexander Fleming in 1928.\",\n",
    "    \"The Apollo 11 mission landed on the moon in 1969.\",\n",
    "    \"Nigeria‚Äôs current president is Bola Ahmed Tinubu.\"\n",
    "]\n",
    "\n",
    "# Create embeddings\n",
    "doc_embeddings = embedder.encode(docs)\n",
    "index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "index.add(np.array(doc_embeddings))\n",
    "\n",
    "def retrieve_context(query):\n",
    "    q_emb = embedder.encode([query])\n",
    "    _, idx = index.search(np.array(q_emb), 1)\n",
    "    return docs[idx[0][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b40a1b-cba0-4a97-830f-39fcd45fd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    context = retrieve_context(query)\n",
    "    prompt = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50567efa-b128-4484-87ba-32fe495e6901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def rag_pipeline(query):\n",
    "    return generate_answer(query)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=rag_pipeline,\n",
    "    inputs=gr.Textbox(label=\"Ask a Question\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üß† The RAG-AI-Assistant\",\n",
    "    description=\"Ask factual questions ‚Äî powered by FAISS, FLAN-T5, and Sentence Transformers.\"\n",
    ")\n",
    "\n",
    "demo.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446162d5-4b25-4a47-b8e3-72082e0d3320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
